{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8364e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# Loads variables from the environment\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "open_api_key = getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Print output of message type\n",
    "import json\n",
    "def print_msg(message):\n",
    "    print(json.dumps(message.model_dump(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c203b",
   "metadata": {},
   "source": [
    "### Basic request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf0136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"msg_01UT4KK9FJtQjS9eGTrC9Lxh\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"citations\": null,\n",
      "      \"text\": \"Hello! How are you doing today? Is there something I can help you with?\",\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"claude-opus-4-6\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"stop_reason\": \"end_turn\",\n",
      "  \"stop_sequence\": null,\n",
      "  \"type\": \"message\",\n",
      "  \"usage\": {\n",
      "    \"cache_creation\": {\n",
      "      \"ephemeral_1h_input_tokens\": 0,\n",
      "      \"ephemeral_5m_input_tokens\": 0\n",
      "    },\n",
      "    \"cache_creation_input_tokens\": 0,\n",
      "    \"cache_read_input_tokens\": 0,\n",
      "    \"inference_geo\": \"global\",\n",
      "    \"input_tokens\": 10,\n",
      "    \"output_tokens\": 20,\n",
      "    \"server_tool_use\": null,\n",
      "    \"service_tier\": \"standard\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = anthropic.Anthropic().messages.create(\n",
    "    model=\"claude-opus-4-6\",\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, Claude\"}],\n",
    ")\n",
    "print_msg(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442bfa4",
   "metadata": {},
   "source": [
    "### Multiple conversational turns\n",
    "\n",
    "The Messages API is stateless, which means that you always send the full conversational history to the API. You can use this pattern to build up a conversation over time. Earlier conversational turns don't necessarily need to actually originate from Claude â€” you can use synthetic `assistant` messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0844366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"msg_01Q2DnUwwTdCKvYnjXDroWp1\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"citations\": null,\n",
      "      \"text\": \"# Large Language Models (LLMs)\\n\\nLarge Language Models are AI systems trained to understand and generate human language. Here's a breakdown:\\n\\n## What They Are\\n- **Neural networks** with billions (or even trillions) of parameters\\n- Trained on massive amounts of text data from books, websites, articles, and other sources\\n- Designed to predict and generate text based on patterns learned during training\\n\\n## How They Work\\n1. **Training**: They process enormous datasets, learning statistical patterns in language \\u2014 grammar, facts, reasoning patterns, writing styles, etc.\\n2. **Prediction**: At their core, they work by predicting the most likely next word (or token) in a sequence\\n3. **Transformer Architecture**: Most modern LLMs use the \\\"transformer\\\" architecture, which is particularly good at understanding context and relationships between words\\n\\n## Key Capabilities\\n- Answering questions\\n- Writing and summarizing text\\n- Translation\\n- Coding\\n- Reasoning and analysis\\n- Conversation\\n\\n## Limitations\\n- They can **\\\"hallucinate\\\"** \\u2014 generating plausible-sounding but incorrect information\\n- Their knowledge has a **training cutoff date**\\n- They don't truly \\\"understand\\\" in the way humans do \\u2014 they work with statistical patterns\\n- They can reflect **biases** present in their training data\\n\\n## Examples\\nGPT-4, Claude (that's me!), LLaMA, Gemini, and Mistral are all examples of LLMs.\\n\\nWould you like me to go deeper into any particular aspect?\",\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"claude-opus-4-6\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"stop_reason\": \"end_turn\",\n",
      "  \"stop_sequence\": null,\n",
      "  \"type\": \"message\",\n",
      "  \"usage\": {\n",
      "    \"cache_creation\": {\n",
      "      \"ephemeral_1h_input_tokens\": 0,\n",
      "      \"ephemeral_5m_input_tokens\": 0\n",
      "    },\n",
      "    \"cache_creation_input_tokens\": 0,\n",
      "    \"cache_read_input_tokens\": 0,\n",
      "    \"inference_geo\": \"global\",\n",
      "    \"input_tokens\": 27,\n",
      "    \"output_tokens\": 339,\n",
      "    \"server_tool_use\": null,\n",
      "    \"service_tier\": \"standard\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = anthropic.Anthropic().messages.create(\n",
    "    model=\"claude-opus-4-6\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello!\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you describe LLMs to me?\"},\n",
    "    ],\n",
    ")\n",
    "print_msg(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699aa27",
   "metadata": {},
   "source": [
    "### Vision\n",
    "\n",
    "Claude can read both text and images in requests. We support both `base64` and `url` source types for images, and the `image/jpeg`, `image/png`, `image/gif`, and `image/webp` media types. See our [vision guide](https://platform.claude.com/docs/en/build-with-claude/vision) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca681695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
