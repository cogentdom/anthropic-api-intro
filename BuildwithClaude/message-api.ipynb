{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "af8364e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "# Loads variables from the environment\n",
        "from os import getenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "open_api_key = getenv(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "# Print output of message type\n",
        "import json\n",
        "def print_msg(message):\n",
        "    print(json.dumps(message.model_dump(), indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780c203b",
      "metadata": {},
      "source": [
        "### Basic request and response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7cf0136d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"msg_01BhRxTHzky9WCALum24Wf4N\",\n",
            "  \"content\": [\n",
            "    {\n",
            "      \"citations\": null,\n",
            "      \"text\": \"Hello! How are you doing today? Is there something I can help you with?\",\n",
            "      \"type\": \"text\"\n",
            "    }\n",
            "  ],\n",
            "  \"model\": \"claude-opus-4-6\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"stop_reason\": \"end_turn\",\n",
            "  \"stop_sequence\": null,\n",
            "  \"type\": \"message\",\n",
            "  \"usage\": {\n",
            "    \"cache_creation\": {\n",
            "      \"ephemeral_1h_input_tokens\": 0,\n",
            "      \"ephemeral_5m_input_tokens\": 0\n",
            "    },\n",
            "    \"cache_creation_input_tokens\": 0,\n",
            "    \"cache_read_input_tokens\": 0,\n",
            "    \"inference_geo\": \"global\",\n",
            "    \"input_tokens\": 10,\n",
            "    \"output_tokens\": 20,\n",
            "    \"server_tool_use\": null,\n",
            "    \"service_tier\": \"standard\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "message = anthropic.Anthropic().messages.create(\n",
        "    model=\"claude-opus-4-6\",\n",
        "    max_tokens=1024,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello, Claude\"}],\n",
        ")\n",
        "print_msg(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d442bfa4",
      "metadata": {},
      "source": [
        "### Multiple conversational turns\n",
        "\n",
        "The Messages API is stateless, which means that you always send the full conversational history to the API. You can use this pattern to build up a conversation over time. Earlier conversational turns don't necessarily need to actually originate from Claude â€” you can use synthetic `assistant` messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a0844366",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"msg_018y2rnr8Bf2Tuqk3KWck5N3\",\n",
            "  \"content\": [\n",
            "    {\n",
            "      \"citations\": null,\n",
            "      \"text\": \"# Large Language Models (LLMs)\\n\\nLarge Language Models are AI systems trained to understand and generate human language. Here's a breakdown:\\n\\n## What They Are\\n- Neural networks with **billions of parameters** (adjustable weights)\\n- Trained on massive amounts of text data from books, websites, articles, and other sources\\n- Designed to predict and generate text based on patterns learned during training\\n\\n## How They Work\\n- At their core, they predict **the next most likely word (or token)** in a sequence\\n- They use a architecture called a **Transformer**, which helps them understand context and relationships between words\\n- They process text as \\\"tokens\\\" \\u2014 chunks of words or characters\\n\\n## Key Capabilities\\n- Answering questions\\n- Writing and summarizing text\\n- Translation\\n- Coding assistance\\n- Reasoning and analysis\\n- Conversation\\n\\n## Limitations\\n- They can **\\\"hallucinate\\\"** \\u2014 generate plausible-sounding but incorrect information\\n- Their knowledge has a **training cutoff date**\\n- They don't truly \\\"understand\\\" in the way humans do \\u2014 they work through sophisticated pattern matching\\n- They can reflect **biases** present in their training data\\n\\n## Examples\\n- **GPT** (OpenAI)\\n- **Claude** (Anthropic) \\u2014 that's me!\\n- **LLaMA** (Meta)\\n- **Gemini** (Google)\\n\\nWould you like me to dive deeper into any particular aspect?\",\n",
            "      \"type\": \"text\"\n",
            "    }\n",
            "  ],\n",
            "  \"model\": \"claude-opus-4-6\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"stop_reason\": \"end_turn\",\n",
            "  \"stop_sequence\": null,\n",
            "  \"type\": \"message\",\n",
            "  \"usage\": {\n",
            "    \"cache_creation\": {\n",
            "      \"ephemeral_1h_input_tokens\": 0,\n",
            "      \"ephemeral_5m_input_tokens\": 0\n",
            "    },\n",
            "    \"cache_creation_input_tokens\": 0,\n",
            "    \"cache_read_input_tokens\": 0,\n",
            "    \"inference_geo\": \"global\",\n",
            "    \"input_tokens\": 27,\n",
            "    \"output_tokens\": 322,\n",
            "    \"server_tool_use\": null,\n",
            "    \"service_tier\": \"standard\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "message = anthropic.Anthropic().messages.create(\n",
        "    model=\"claude-opus-4-6\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello, Claude\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you describe LLMs to me?\"},\n",
        "    ],\n",
        ")\n",
        "print_msg(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e699aa27",
      "metadata": {},
      "source": [
        "### Vision\n",
        "\n",
        "Claude can read both text and images in requests. We support both `base64` and `url` source types for images, and the `image/jpeg`, `image/png`, `image/gif`, and `image/webp` media types. See our [vision guide](https://platform.claude.com/docs/en/build-with-claude/vision) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5895e8c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eadcfb99",
      "metadata": {},
      "source": [
        "##### Option 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ca681695",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"msg_01BnhWM6VgqAWRpFQ4LE5jUq\",\n",
            "  \"content\": [\n",
            "    {\n",
            "      \"citations\": null,\n",
            "      \"text\": \"# Ant in Macro Photography\\n\\nThe image shows a **single ant** captured in stunning **macro (close-up) photography**. The ant appears to be a **black or carpenter ant**, and it's standing on what looks like a concrete or stone surface.\\n\\nWhat makes this photo particularly striking is the ant's **posture** \\u2014 it appears to be rearing up with its head and front legs raised, almost in a defensive or alert stance, with its abdomen (gaster) touching or near the ground. You can clearly see the ant's:\\n\\n- **Three distinct body segments** (head, thorax, abdomen)\\n- **Long antennae**\\n- **Six legs** with fine detail\\n- **Fine hairs (setae)** on the abdomen\\n- **Mandibles** near the head\\n\\nThe background is beautifully **blurred (bokeh effect)**, with warm tones of brown and pink, keeping the focus entirely on the ant. This is an excellent example of nature/insect macro photography.\",\n",
            "      \"type\": \"text\"\n",
            "    }\n",
            "  ],\n",
            "  \"model\": \"claude-opus-4-6\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"stop_reason\": \"end_turn\",\n",
            "  \"stop_sequence\": null,\n",
            "  \"type\": \"message\",\n",
            "  \"usage\": {\n",
            "    \"cache_creation\": {\n",
            "      \"ephemeral_1h_input_tokens\": 0,\n",
            "      \"ephemeral_5m_input_tokens\": 0\n",
            "    },\n",
            "    \"cache_creation_input_tokens\": 0,\n",
            "    \"cache_read_input_tokens\": 0,\n",
            "    \"inference_geo\": \"global\",\n",
            "    \"input_tokens\": 1554,\n",
            "    \"output_tokens\": 224,\n",
            "    \"server_tool_use\": null,\n",
            "    \"service_tier\": \"standard\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Option 1: Base64-encoded image\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
        "image_media_type = \"image/jpeg\"\n",
        "image_data = base64.standard_b64encode(\n",
        "    httpx.get(image_url, headers={\"User-Agent\": \"AnthropicAPIIntro/1.0\"}).content\n",
        ").decode(\"utf-8\")\n",
        "\n",
        "message = anthropic.Anthropic().messages.create(\n",
        "    model=\"claude-opus-4-6\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": image_media_type,\n",
        "                        \"data\": image_data,\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in the above image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "print_msg(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f95a9044",
      "metadata": {},
      "source": [
        "##### Option 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "acf67c15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"msg_019fvLSRfBY1dmnyf7xNe2U1\",\n",
            "  \"content\": [\n",
            "    {\n",
            "      \"citations\": null,\n",
            "      \"text\": \"# Ant in Macro Photography\\n\\nThe image shows a **single ant** captured in stunning **macro (close-up) photography**. The ant appears to be a **black or carpenter ant** standing on a rough, concrete-like surface.\\n\\n## Notable details:\\n\\n- **Pose**: The ant is in a striking upright position, with its head and front legs raised, almost as if it's rearing up or grooming itself\\n- **Body segments**: The three main body parts (head, thorax, and abdomen/gaster) are clearly visible\\n- **Features**: You can see its antennae, mandibles, long legs, and fine hairs (setae) on its abdomen\\n- **Background**: The background is beautifully blurred (bokeh effect), with warm tones of brown and dark hues\\n- **Lighting**: The photograph has excellent lighting that highlights the ant's exoskeleton texture and sheen\\n\\nThis is a remarkably detailed and well-composed macro photograph that showcases the intricate anatomy of what appears to be a species from the genus *Camponotus* (carpenter ant) or possibly a *Formica* species.\",\n",
            "      \"type\": \"text\"\n",
            "    }\n",
            "  ],\n",
            "  \"model\": \"claude-opus-4-6\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"stop_reason\": \"end_turn\",\n",
            "  \"stop_sequence\": null,\n",
            "  \"type\": \"message\",\n",
            "  \"usage\": {\n",
            "    \"cache_creation\": {\n",
            "      \"ephemeral_1h_input_tokens\": 0,\n",
            "      \"ephemeral_5m_input_tokens\": 0\n",
            "    },\n",
            "    \"cache_creation_input_tokens\": 0,\n",
            "    \"cache_read_input_tokens\": 0,\n",
            "    \"inference_geo\": \"global\",\n",
            "    \"input_tokens\": 1554,\n",
            "    \"output_tokens\": 256,\n",
            "    \"server_tool_use\": null,\n",
            "    \"service_tier\": \"standard\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Option 2: URL-referenced image\n",
        "message_from_url = anthropic.Anthropic().messages.create(\n",
        "    model=\"claude-opus-4-6\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"url\",\n",
        "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\",\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"What is in the above image?\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "print_msg(message_from_url)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
